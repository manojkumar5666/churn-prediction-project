{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjJCK94v_YMk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Customer Churn Prediction – Model Training Notebook\n",
        "\n",
        "This notebook covers:\n",
        "\n",
        "- Data Cleaning\n",
        "- Feature Engineering\n",
        "- Model Training (Logistic, RF, XGBoost)\n",
        "- Evaluation (Accuracy, AUC, ROC, PR Curve)\n",
        "- Saving Final Model and Scaler\n",
        "\n",
        "Dataset: Telco Customer Churn Dataset from IBM.\n"
      ],
      "metadata": {
        "id": "ihKyEVLG_qtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load raw dataset\n",
        "df = pd.read_csv('/content/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "print(\"Original shape:\", df.shape)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "xz5RaSjK_zpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'TotalCharges' to numeric and drop missing values\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df.dropna(subset=['TotalCharges'], inplace=True)\n",
        "\n",
        "# Drop customerID (not needed for modeling)\n",
        "df.drop('customerID', axis=1, inplace=True)\n",
        "\n",
        "# Save cleaned data\n",
        "df.to_csv('cleaned_telco_churn.csv', index=False)\n",
        "print(\"Cleaned and saved!\")\n"
      ],
      "metadata": {
        "id": "iNFDSd6D_6Mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/cleaned_telco_churn.csv')\n",
        "\n",
        "# Count how many services customer has\n",
        "service_cols = ['PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity',\n",
        "                'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
        "                'StreamingTV', 'StreamingMovies']\n",
        "df['ServiceCount'] = df[service_cols].apply(lambda row: sum(row == 'Yes'), axis=1)\n",
        "\n",
        "# Create TenureGroup\n",
        "def tenure_group(tenure):\n",
        "    if tenure <= 12:\n",
        "        return '0–1 year'\n",
        "    elif tenure <= 24:\n",
        "        return '1–2 years'\n",
        "    elif tenure <= 48:\n",
        "        return '2–4 years'\n",
        "    elif tenure <= 60:\n",
        "        return '4–5 years'\n",
        "    else:\n",
        "        return '5+ years'\n",
        "df['TenureGroup'] = df['tenure'].apply(tenure_group)\n",
        "\n",
        "# Monthly charges bucket\n",
        "def charges_bucket(charge):\n",
        "    if charge < 35:\n",
        "        return 'Low'\n",
        "    elif charge < 70:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'High'\n",
        "df['MonthlyChargesBucket'] = df['MonthlyCharges'].apply(charges_bucket)\n",
        "\n",
        "# Convert Yes/No to 1/0\n",
        "df['SeniorCitizen'] = df['SeniorCitizen'].replace({1: 'Yes', 0: 'No'})\n",
        "df.replace({'Yes': 1, 'No': 0}, inplace=True)\n",
        "\n",
        "# One-hot encode categorical features\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Save preprocessed data\n",
        "df.to_csv('final_preprocessed_churn.csv', index=False)\n",
        "print(\"Feature engineering complete. Final shape:\", df.shape)\n"
      ],
      "metadata": {
        "id": "x_zVdyOcAEMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "# Load final data\n",
        "df = pd.read_csv('final_preprocessed_churn.csv')\n",
        "X = df.drop('Churn', axis=1)\n",
        "y = df['Churn']\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "JaAbKQEbAOHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "logreg = LogisticRegression(max_iter=2000)\n",
        "logreg.fit(X_train, y_train)\n",
        "print(\"LogReg Accuracy:\", accuracy_score(y_test, logreg.predict(X_test)))\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "print(\"RF Accuracy:\", accuracy_score(y_test, rf.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "OPEEeGllAS0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb = XGBClassifier(eval_metric='logloss')\n",
        "xgb.fit(X_train, y_train)\n",
        "print(\"XGBoost Accuracy:\", accuracy_score(y_test, xgb.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "nPd7sgMNAXZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [3, 5],\n",
        "    'learning_rate': [0.01, 0.1]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(XGBClassifier(eval_metric='logloss'),\n",
        "                    param_grid,\n",
        "                    scoring='roc_auc',\n",
        "                    cv=3,\n",
        "                    verbose=1)\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "best_xgb = grid.best_estimator_\n"
      ],
      "metadata": {
        "id": "X3W0msWKAfKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve\n",
        "\n",
        "# Confusion matrix\n",
        "y_pred = best_xgb.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "ConfusionMatrixDisplay(cm).plot()\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Classification Report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, best_xgb.predict_proba(X_test)[:,1])\n",
        "plt.plot(fpr, tpr)\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# PR Curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, best_xgb.predict_proba(X_test)[:,1])\n",
        "plt.plot(recall, precision)\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XSND4EdqAj8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the final best model\n",
        "joblib.dump(best_xgb, 'churn_model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "print(\"✅ Model and scaler saved!\")\n"
      ],
      "metadata": {
        "id": "FFnKBvKkApx-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}